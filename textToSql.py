import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.utilities import SQLDatabase
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from typing import TypedDict, List, Optional
from langgraph.graph import StateGraph, START, END

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")  

class SQLResponse(BaseModel):
    sql: str = Field(description="SQL ì¿¼ë¦¬")

class SQLState(TypedDict, total=False):
    question: str
    schema_context: str
    sql: str
    results: List[str]
    source: str #normal / fallback
class EcommerceTextToSQLAgent:
    def __init__(self):
        print("RAG ì´ˆê¸°í™”...")
        self.db = SQLDatabase.from_uri(DATABASE_URL)
        
        self.embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        self.vector_store = Chroma(persist_directory="./chroma_vectors", embedding_function=self.embeddings)
        
        self._init_schema_vectors()

        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
            self.sql_chain = self._create_sql_chain()

        # LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        self.graph = self._create_graph()

        print("RAG ì¤€ë¹„ ì™„ë£Œ !!!!")
       
    # Vector storeì— DB ìŠ¤í‚¤ë§ˆ ì €ì¥
    # def _init_schema_vectors(self):
    #     schema_text = self._get_schema()
    #     tables = self.db.get_usable_table_names()
        
    #     schema_texts = [
    #         schema_text,
    #         "Ecommerce DB: ìƒí’ˆ(item), ì˜µì…˜(item_option), ì¿ í°(coupon), êµ¬ë§¤(purchase_detail), êµ¬ë§¤ìƒí’ˆì¡°ì¸(purchase_item), ë¦¬ë·°(review), ìœ ì €(user)",
    #         "INSERT ì˜ˆì‹œ: INSERT INTO item (item_name, item_price) VALUES ('ìƒí’ˆëª…', 10000)",
    #         "Join ì˜ˆì‹œ: SELECT i.item_name, SUM(pd.quantity) FROM item i JOIN purchase_detail pd"
    #     ]
    #     self.vector_store.add_texts(schema_texts) #TODO: embedingì‹œ í…Œì´ë¸” ë©”íƒ€ ì •ë³´ ë§¤í•‘
    #     print(f"DB ìŠ¤í‚¤ë§ˆ ë²¡í„°í™”: {len(tables)} í…Œì´ë¸”")

    # Vector storeì— DB ìŠ¤í‚¤ë§ˆ ì €ì¥
    def _init_schema_vectors(self):
        schema_text = self._get_schema()
        tables = self.db.get_usable_table_names()
        
        table_meta_mapping = {
            "coupon": {
                "desc": "ì¿ í° ê´€ë¦¬ í…Œì´ë¸”",
                "columns": "coupon_name(ì¿ í°ëª…), discount_rate(í• ì¸ìœ¨%), started_date(ì‹œì‘ì¼!), ended_date(ì¢…ë£Œì¼!), user_id(ìœ ì €ID), created_date(ìƒì„±ì¼), used_date(ì‚¬ìš©ì¼)",
                "keywords": ["ì¿ í°", "í• ì¸", "ì‹œì‘ì¼", "ì¢…ë£Œì¼", "í”„ë¡œëª¨ì…˜", "ì¿ í°ëª…", "í• ì¸ìœ¨"],
                "example": "INSERT INTO coupon (coupon_name, discount_rate, started_date, ended_date, user_id) VALUES ('í¬ë¦¬ìŠ¤ë§ˆìŠ¤', 20, '2025-12-25 00:00:00', '2025-12-31 23:59:59', 1);"
            },
            "item": {
                "desc": "ìƒí’ˆ ê¸°ë³¸ ì •ë³´ í…Œì´ë¸”",
                "columns": "item_id(PK), item_name(ìƒí’ˆëª…!), item_price(ê°€ê²©), item_image_url(ì´ë¯¸ì§€URL), description(ì„¤ëª…), deleted_status(ì‚­ì œì—¬ë¶€)",
                "keywords": ["ìƒí’ˆ", "ì œí’ˆ", "ì•„ì´í…œ", "ê°€ê²©", "ì´ë¯¸ì§€", "ì„¤ëª…"],
                "example": "INSERT INTO item (item_name, item_price) VALUES ('í‹°ì…”ì¸ ', 15000);"
            },
            "item_option": {
                "desc": "ìƒí’ˆ ì˜µì…˜ í…Œì´ë¸” (ìƒ‰ìƒ, ì‚¬ì´ì¦ˆ, ì¬ê³ )",
                "columns": "i_option_id(PK), i_option_name(ì˜µì…˜ëª…!), i_option_quantity(ì¬ê³ ëŸ‰), item_id(ìƒí’ˆID), deleted_status(ì‚­ì œì—¬ë¶€)",
                "keywords": ["ì˜µì…˜", "ìƒ‰ìƒ", "ì‚¬ì´ì¦ˆ", "ì¬ê³ ", "ì˜µì…˜ëª…", "ìˆ˜ëŸ‰"],
                "example": "INSERT INTO item_option (i_option_name, i_option_quantity, item_id) VALUES ('ë¹¨ê°•-M', 100, 1);"
            },
            "purchase_detail": {
                "desc": "êµ¬ë§¤ ì£¼ë¬¸ ë‚´ì—­ í…Œì´ë¸” (ë°°ì†¡ìƒíƒœ í¬í•¨)",
                "columns": "purchase_id(PK), user_id(êµ¬ë§¤ìID), quantity(êµ¬ë§¤ìˆ˜ëŸ‰), purchase_date(êµ¬ë§¤ì¼), delivery_status(ë°°ì†¡ìƒíƒœ: BEFORE_DELIVERY|COMPLETED|...)",
                "keywords": ["êµ¬ë§¤", "ì£¼ë¬¸", "ë°°ì†¡", "ìˆ˜ëŸ‰", "ë°°ì†¡ìƒíƒœ"],
                "example": "SELECT * FROM purchase_detail WHERE delivery_status='COMPLETED';"
            },
            "purchase_item": {
                "desc": "êµ¬ë§¤-ì˜µì…˜ ë‹¤ëŒ€ë‹¤ ì¡°ì¸ í…Œì´ë¸”",
                "columns": "purchase_id(FK), option_id(FK) (ë³µí•©PK)",
                "keywords": ["êµ¬ë§¤ìƒí’ˆ", "ì£¼ë¬¸ì˜µì…˜", "êµ¬ë§¤ë‚´ì—­"],
                "example": "SELECT pi.*, io.i_option_name FROM purchase_item pi JOIN item_option io ON pi.option_id=io.i_option_id;"
            },
            "review": {
                "desc": "ìƒí’ˆ ë¦¬ë·° í…Œì´ë¸”",
                "columns": "review_id(PK), review_score(ë³„ì  1-5), comment(ë¦¬ë·°ë‚´ìš©), item_id(ìƒí’ˆID), purchase_id(êµ¬ë§¤ID), deleted_status(ì‚­ì œì—¬ë¶€)",
                "keywords": ["ë¦¬ë·°", "í›„ê¸°", "ë³„ì ", "í‰ì ", "ëŒ“ê¸€"],
                "example": "INSERT INTO review (review_score, comment, item_id, purchase_id) VALUES (5, 'ì¢‹ì•„ìš”', 1, 1);"
            },
            "user": {
                "desc": "íšŒì› í…Œì´ë¸”",
                "columns": "user_id(PK), email(ì´ë©”ì¼), password(ë¹„ë°€ë²ˆí˜¸), user_role(USER|ADMIN), address_road(ë„ë¡œëª…ì£¼ì†Œ), address_detail(ìƒì„¸ì£¼ì†Œ), deleted_status(ì‚­ì œì—¬ë¶€)",
                "keywords": ["ìœ ì €", "íšŒì›", "ì‚¬ìš©ì", "email", "ì´ë©”ì¼", "ì£¼ì†Œ"],
                "example": "SELECT user_id FROM user WHERE email LIKE '%user1%';"
            }
        }
        
        schema_texts = [schema_text]
        
        for table_name, meta in table_meta_mapping.items():
            if table_name in tables:
                meta_text = f"""ğŸ“‹ {table_name} í…Œì´ë¸” ({meta['desc']})

                [ì£¼ìš” ì»¬ëŸ¼]:
                {meta['columns']}

                [ê²€ìƒ‰ í‚¤ì›Œë“œ]: {', '.join(meta['keywords'])}

                [ì‚¬ìš© ì˜ˆì‹œ]:
                {meta['example']}

                [ì£¼ì˜ì‚¬í•­]:
                - AUTO_INCREMENT ì»¬ëŸ¼(coupon_id, item_id ë“±)ì€ ìƒëµ
                - created_date, modified_dateëŠ” ìë™ ìƒì„±
                - userëŠ” emailë¡œ ê²€ìƒ‰ (user_name ì»¬ëŸ¼ ì—†ìŒ)"""

        schema_texts.append(meta_text)
        
        common_patterns = [
            "ì¡°ì¸ ì˜ˆì‹œ: SELECT i.item_name, pd.quantity FROM item i JOIN purchase_detail pd ON i.item_id=pd.user_id;",
            "í†µê³„ ì˜ˆì‹œ: SELECT AVG(review_score), COUNT(*) FROM review GROUP BY item_id;",
            "ë‚ ì§œ ì˜ˆì‹œ: '2025-12-25 00:00:00' ë˜ëŠ” NOW(), DATE_ADD(NOW(), INTERVAL 7 DAY)",
            "Enum ì˜ˆì‹œ: delivery_status IN ('BEFORE_DELIVERY', 'COMPLETED', 'DELIVERY_IN_PROGRESS')"
        ]
        schema_texts.extend(common_patterns)
        
        self.vector_store.add_texts(schema_texts)
        print(f"DB ìŠ¤í‚¤ë§ˆ ë²¡í„°í™” ì™„ë£Œ!")
        print(f"í…Œì´ë¸”: {len(tables)}ê°œ")
        print(f"ë©”íƒ€ ë¬¸ì„œ: {len(schema_texts)-1}ê°œ")


    # DB ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°
    def _get_schema(self):
        tables = self.db.get_usable_table_names()
        schema_info = []
        
        for table in tables:
            columns = self.db.get_table_info([table])
            schema_info.append(f"{table}: {columns}") #TODO: í”„ë¡¬í”„íŠ¸ë¡œë„ ë§ì´ í•¨.
        
        return "\n".join(schema_info)
    
    # Few shot
    def _create_sql_chain(self):

        base_parser = PydanticOutputParser(pydantic_object=SQLResponse)

        parser = OutputFixingParser.from_llm(
            parser=base_parser,
            llm=self.llm
        )

        few_shot = """
        ì˜ˆì‹œ 1: "í‹°ì…”ì¸  10000ì› ì¶”ê°€" â†’ INSERT INTO item (item_name, item_price) VALUES ('í‹°ì…”ì¸ ', 10000);
        ì˜ˆì‹œ 2: "ë¹¨ê°„ìƒ‰ ì˜µì…˜ 100ê°œ" â†’ INSERT INTO item_option (i_option_name, i_option_quantity) VALUES ('ë¹¨ê°„ìƒ‰', 100);
        ì˜ˆì‹œ 3: "ìƒí’ˆ ëª©ë¡" â†’ SELECT * FROM item LIMIT 10;
        ì˜ˆì‹œ 4: "ì´ ë§¤ì¶œ" â†’ SELECT SUM(item_price * quantity) FROM item i JOIN purchase_detail pd ON i.item_id = pd.item_id;
        ì˜ˆì‹œ 5: "ë¸”ë™í”„ë¼ì´ë°ì´ ì¿ í°" â†’ INSERT INTO coupon (coupon_name, discount_rate, started_date, ended_date, user_id) VALUES ('í¬ë¦¬ìŠ¤ë§ˆìŠ¤', 20, '2025-12-25 00:00:00', '2025-12-31 23:59:59', 1);
        ì˜ˆì‹œ 6: "user1 ì¿ í°" â†’ INSERT INTO coupon (coupon_name, discount_rate, started_date, ended_date, user_id) VALUES ('í…ŒìŠ¤íŠ¸', 10, NOW(), DATE_ADD(NOW(), INTERVAL 7 DAY), (SELECT user_id FROM user WHERE email='user1@example.com'));
        """ 
                
        template = """Ecommerce MySQL ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.

        [ì‹¤ì‹œê°„ DB ìŠ¤í‚¤ë§ˆ]:
        {schema_context}

        [ì‚¬ìš© ì˜ˆì‹œ]:
        """ + few_shot + """

        [ì‚¬ìš©ì ì§ˆë¬¸]:
        {question}

        [ì¶œë ¥ í˜•ì‹]:
        ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹
        í˜•ì‹:
        {{
        "sql": "SQLë¬¸;"
        }}

        [ì¶œë ¥ í˜•ì‹ ì—„ìˆ˜]:
        1. í•œ ì¤„ SQLë§Œ ì¶œë ¥ (ì¤„ë°”ê¿ˆ X)
        2. ë§¨ ëì— ì„¸ë¯¸ì½œë¡ (;) í•˜ë‚˜ë§Œ (ì„¸ë¯¸ì½œë¡  ì—¬ëŸ¬ê°œ X)
        3. ë°±í‹±(`) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        4. ë§ˆí¬ë‹¤ìš´(```) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        5. ì£¼ì„(--) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ 
        6. ë”°ì˜´í‘œ ë“± ê¸ˆì§€
        7. ì™„ì „í•œ SQLë§Œ í•œ ì¤„ (ëŠê¸°ë©´ ì•ˆë¨)
        8.ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹

        [ì§€ì‹œì‚¬í•­]:
        1. ì‹¤ì œ ìŠ¤í‚¤ë§ˆë§Œ ì‚¬ìš© (item, item_option, coupon, purchase, review)
        2. ë°±í‹±(`)ê³¼ ë§ˆí¬ë‹¤ìš´(```) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        3. AUTO_INCREMENT ìƒëµ
        4. datetime í˜•ì‹: 'YYYY-MM-DD HH:MM:SS'
        5. ë³µì¡ ì¿¼ë¦¬ëŠ” ì¡°ì¸/ì„œë¸Œì¿¼ë¦¬ ì‚¬ìš© OK
        6. ëª¨ë“  í…Œì´ë¸”ì˜ created_dateëŠ” í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©

        SQL:""" #TODO: ê°œí–‰ì´ë‚˜ í…ìŠ¤íŠ¸ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        
        prompt = ChatPromptTemplate.from_template(template)

        return prompt | self.llm | parser
        #LCEL ì²´ì¸ : í”„ë¡¬í”„íŠ¸ì™€ LLMì„ | ì—°ì‚°ìë¡œ ì—°ê²°í•˜ì—¬ ì‘ì„±í•˜ì—¬ ì²´ì¸ì„ êµ¬í˜„
        #prompt í•œë²ˆ ë” formatí•  í•„ìš” x
        #TODO: pydeantic parserë¡œ (ë²”ìš©ì„±ì´ í¬ë‹¤)
    
    
    def _safe_execute(self, clean_sql: str):
        results = []
        for sql_query in clean_sql.split(';'):
            sql_query = sql_query.strip()
            if sql_query:
                try:
                    result = self.db.run(sql_query)
                    results.append(f"{result}")
                    print(f"SQL Query ì‹¤í–‰: {sql_query[:50]}...")
                except Exception as e:
                    results.append(f"{str(e)[:50]}...")
                    print(f"SQL Query ì‹¤í–‰ ì‹¤íŒ¨: {sql_query[:50]}...")
        return results
    
    def execute_query(self, natural_query: str): 
        try:
            # LangGraph ì´ˆê¸° ìƒíƒœ
            init_state: SQLState = {
                "question": natural_query
            }

            # graph.invoke ì‚¬ìš© (ë‹¨ì¼ ì‹¤í–‰)
            final_state: SQLState = self.graph.invoke(init_state)

            rag_context = final_state.get("schema_context", "")
            sql = final_state.get("sql", "")
            results = final_state.get("results", [])
            source = final_state.get("source", "normal")

            return {
                "status": "success",
                "result": {
                    "query": natural_query,
                    "rag_context": rag_context[:200],
                    "sql": sql,
                    "results": results,
                    "source": source,
                },
            }

        except Exception as e:
            print(f"error message: {str(e)}")
            return {"status": "error", "error": str(e)}

    # LangGraph node: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰
    def _node_retrieve_schema(self, state: SQLState) -> SQLState:
        question = state["question"]
        relevant_docs = self.vector_store.similarity_search(question, k=2)
        rag_context = "\n".join([doc.page_content for doc in relevant_docs])
        print(f"RAG ìŠ¤í‚¤ë§ˆ: {rag_context[:100]}...")
        return {
            **state,
            "schema_context": rag_context,
        }
    def _node_generate_sql(self, state: SQLState) -> SQLState:
        if not (self.llm and self.sql_chain):
            return {**state, "source": "fallback"}
        
        try:
            invoke_result = self.sql_chain.invoke({
                "schema_context": state.get("schema_context", ""),
                "question": state["question"],
            })
            sql = str(invoke_result.sql).strip()
            print(f"SQL: {repr(sql)}...")
            return {
                **state,
                "sql": sql,
                "source": "normal",
            }
        except Exception as e:
            print(f"SQL ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                **state,
                "source": "fallback",
            }
        
    # LangGraph node: SQL ì‹¤í–‰ ë° fallback ì²˜ë¦¬
    def _node_run_sql(self, state: SQLState) -> SQLState:
        source = state.get("source", "normal")
        sql = state.get("sql", "").strip()

        # LLM ì •ìƒ SQL ì—†ëŠ” ê²½ìš° â†’ fallback SQL ìƒì„±
        if source == "fallback" or not sql:
            print("Fallback ëª¨ë“œ ì‹¤í–‰...")
            fallback_sql = self._generate_fallback_sql(state["question"])
            results = self._safe_execute(fallback_sql)
            return {
                **state,
                "sql": fallback_sql,
                "results": results,
                "source": "fallback",
            }

        # ì •ìƒ SQL ì‹¤í–‰
        results = self._safe_execute(sql)
        return {
            **state,
            "results": results,
        }
    
    def _create_graph(self):
        builder = StateGraph(SQLState)

        # ë…¸ë“œ ë“±ë¡
        builder.add_node("retrieve_schema", self._node_retrieve_schema)
        builder.add_node("generate_sql", self._node_generate_sql)
        builder.add_node("run_sql", self._node_run_sql)

        # ì—£ì§€ ì—°ê²°
        builder.add_edge(START, "retrieve_schema")
        builder.add_edge("retrieve_schema", "generate_sql")
        builder.add_edge("generate_sql", "run_sql")
        builder.add_edge("run_sql", END)

        # ê·¸ë˜í”„ ì»´íŒŒì¼
        app = builder.compile()
        return app
